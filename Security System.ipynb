{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Recognition with Emotion Recognition and Liveness Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "from fer import FER\n",
    "import smtplib\n",
    "import datetime\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Het\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.preprocessing.label module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.preprocessing. Anything that cannot be imported from sklearn.preprocessing is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\Het\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.21.2 when using version 0.23.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(235, b'2.7.0 Accepted')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protoPath = r'face_detector\\deploy.prototxt'\n",
    "modelPath = r'face_detector\\res10_300x300_ssd_iter_140000.caffemodel'\n",
    "model = load_model('liveness.model')\n",
    "le = pickle.loads(open('le.pickle', \"rb\").read())\n",
    "net = cv2.dnn.readNetFromCaffe(protoPath, modelPath)\n",
    "first_run = True\n",
    "initial_time = datetime.datetime.utcnow()\n",
    "s = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "s.starttls()\n",
    "s.login(\"hetmehta61@gmail.com\", \"cufylheuvyfgmyru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connects to your computer's default camera\n",
    "# 'http://192.168.0.100:8080/video' for remote else 0\n",
    "string = 0\n",
    "cap = cv2.VideoCapture(string)\n",
    "het_image = face_recognition.load_image_file(\"Het_pic.jpg\")\n",
    "het_face_encoding = face_recognition.face_encodings(het_image)[0]\n",
    "detector = FER()\n",
    "\n",
    "known_face_encodings = [\n",
    "    het_face_encoding\n",
    "]\n",
    "\n",
    "known_face_names = [\n",
    "    \"Het Mehta\"\n",
    "]\n",
    "\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "process_this_frame = True\n",
    "# Detect the coordinates\n",
    "face_detector = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capture video from source and perform the facial recognition along with emotion recognition and liveness detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real\n",
      "neutral\n",
      "real\n",
      "neutral\n",
      "real\n",
      "neutral\n",
      "real\n",
      "neutral\n",
      "real\n",
      "neutral\n",
      "real\n",
      "neutral\n",
      "real\n",
      "neutral\n",
      "real\n",
      "neutral\n",
      "real\n",
      "neutral\n",
      "real\n",
      "neutral\n",
      "fake\n",
      "Email Sent\n",
      "neutral\n",
      "real\n",
      "neutral\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "fake\n",
      "neutral\n",
      "real\n",
      "neutral\n",
      "real\n",
      "neutral\n",
      "real\n",
      "neutral\n",
      "real\n",
      "neutral\n",
      "real\n",
      "neutral\n",
      "real\n",
      "neutral\n",
      "real\n",
      "neutral\n",
      "fake\n",
      "neutral\n",
      "real\n",
      "neutral\n",
      "real\n",
      "neutral\n",
      "real\n",
      "neutral\n",
      "No faces found\n",
      "No faces found\n",
      "fake\n",
      "happy\n",
      "fake\n",
      "neutral\n",
      "fake\n",
      "neutral\n",
      "fake\n",
      "neutral\n",
      "fake\n",
      "neutral\n",
      "fake\n",
      "neutral\n",
      "fake\n",
      "neutral\n",
      "fake\n",
      "neutral\n",
      "fake\n",
      "neutral\n",
      "No faces found\n",
      "fake\n",
      "neutral\n",
      "real\n",
      "neutral\n",
      "real\n",
      "neutral\n",
      "real\n",
      "neutral\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(221,\n",
       " b'2.0.0 closing connection s16-20020a63ff50000000b003650ee901e1sm4802055pgk.68 - gsmtp')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if string != 0:\n",
    "        frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)\n",
    "        small_frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)\n",
    "    else:        \n",
    "        small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_detector(gray)\n",
    "\n",
    "    if len(faces) > 0: #Check if there are any faces in the frame        \n",
    "        \n",
    "        rgb_small_frame = small_frame[:, :, ::-1]\n",
    "\n",
    "        if process_this_frame: # Process alternative frames to decrease the load on computer\n",
    "            \n",
    "            #Liveness detection\n",
    "            (h, w) = frame.shape[:2]\n",
    "            blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0,(300, 300), (104.0, 177.0, 123.0))\n",
    "            net.setInput(blob)\n",
    "            detections = net.forward()\n",
    "\n",
    "            for i in range(0, detections.shape[2]):\n",
    "                # extract the confidence (i.e., probability) associated with the\n",
    "                # prediction\n",
    "                confidence = detections[0, 0, i, 2]\n",
    "\n",
    "                # filter out weak detections\n",
    "                if confidence > 0.5:\n",
    "                    # compute the (x, y)-coordinates of the bounding box for\n",
    "                    # the face and extract the face ROI\n",
    "                    box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                    (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "                    # ensure the detected bounding box does fall outside the\n",
    "                    # dimensions of the frame\n",
    "                    startX = max(0, startX)\n",
    "                    startY = max(0, startY)\n",
    "                    endX = min(w, endX)\n",
    "                    endY = min(h, endY)\n",
    "\n",
    "                    # extract the face ROI and then preproces it in the exact\n",
    "                    # same manner as our training data\n",
    "                    face = frame[startY:endY, startX:endX]\n",
    "                    face = cv2.resize(face, (32, 32))\n",
    "                    face = face.astype(\"float\") / 255.0\n",
    "                    face = img_to_array(face)\n",
    "                    face = np.expand_dims(face, axis=0)\n",
    "\n",
    "                    # pass the face ROI through the trained liveness detector\n",
    "                    # model to determine if the face is \"real\" or \"fake\"\n",
    "                    preds = model.predict(face)[0]\n",
    "                    j = np.argmax(preds)\n",
    "                    label = le.classes_[j]\n",
    "                    print(label)\n",
    "                if label == 'fake':\n",
    "                    message = 'Subject: {}\\n\\n{}'.format('SECURITY ALERT FROM HOUSE', \"Someone unauthorized is trying to enter the premises\")\n",
    "                    time_now = datetime.datetime.utcnow()\n",
    "                    if(((time_now - initial_time).total_seconds() > 300) or first_run):\n",
    "                        s.sendmail(\"hetmehta61@gmail.com\", \"hetmehta61@gmail.com\", message)\n",
    "                        print('Email Sent')\n",
    "                        initial_time = time_now\n",
    "                        first_run = False\n",
    "\n",
    "            emotions = detector.detect_emotions(frame) # Detect emotions\n",
    "            for i in emotions:\n",
    "                emotion = i['emotions']\n",
    "                dom_emotion = max(zip(emotion.values(), emotion.keys()))[1]\n",
    "                print(dom_emotion)\n",
    "                if(dom_emotion == 'angry' or dom_emotion == 'fear'): # If extreme emotions alert user\n",
    "                    time_now = datetime.datetime.utcnow()\n",
    "                    if(((time_now - initial_time).total_seconds() > 300) or first_run):\n",
    "                        message = 'Subject: {}\\n\\n{}'.format('SECURITY ALERT FROM HOUSE', \"Someone with extreme emotions detected\")    \n",
    "                        s.sendmail(\"hetmehta61@gmail.com\", \"hetmehta61@gmail.com\", message)\n",
    "                        print('Email Sent')\n",
    "                        initial_time = time_now\n",
    "                        first_run = False\n",
    "\n",
    "            face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "            face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "            face_names = []\n",
    "            for face_encoding in face_encodings:\n",
    "                matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "                name = \"Unknown\"\n",
    "\n",
    "                face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "                best_match_index = np.argmin(face_distances)\n",
    "                if matches[best_match_index]:\n",
    "                    name = known_face_names[best_match_index]\n",
    "\n",
    "                face_names.append(name)\n",
    "    \n",
    "        if 'Unknown' in face_names: # If an unknown person comes, it will alert the user\n",
    "            if(((time_now - initial_time).total_seconds() > 300) or first_run):\n",
    "                message = 'Subject: {}\\n\\n{}'.format('SECURITY ALERT FROM HOUSE', \"Unknown individual at your premises\")\n",
    "                s.sendmail(\"hetmehta61@gmail.com\", \"hetmehta61@gmail.com\", message)\n",
    "                print('Email Sent')\n",
    "                initial_time = time_now\n",
    "                first_run = False\n",
    "\n",
    "        process_this_frame = not process_this_frame\n",
    "\n",
    "\n",
    "        for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "            if string != 0:\n",
    "                top *= 2\n",
    "                right *= 2\n",
    "                bottom *= 2\n",
    "                left *= 2\n",
    "            else:\n",
    "                top *= 4\n",
    "                right *= 4\n",
    "                bottom *= 4\n",
    "                left *= 4\n",
    "\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "        cv2.imshow('Video', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        print('No faces found')\n",
    "        cv2.imshow('Video', frame) \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "s.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3ab3d5f8dec5bf1e3af2739e530a67e4b56b46e5431046229599de570b795f8d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
